{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/03/30 03:13:40] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\Kero/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\Kero/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='e:\\\\Project\\\\AI\\\\Grades\\\\gradesENV\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='C:\\\\Users\\\\Kero/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-30 03:13:45,600] [    INFO] _internal.py:97 - \u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "[2025-03-30 03:13:45,601] [    INFO] _internal.py:97 - \u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/03/30 03:13:49] ppocr DEBUG: dt_boxes num : 20, elapsed : 0.2920217514038086\n",
      "[2025/03/30 03:13:49] ppocr DEBUG: cls num  : 20, elapsed : 0.08571362495422363\n",
      "[2025/03/30 03:13:51] ppocr DEBUG: rec_res num  : 20, elapsed : 1.4660956859588623\n",
      "[2025/03/30 03:13:51] ppocr DEBUG: dt_boxes num : 10, elapsed : 0.17441630363464355\n",
      "[2025/03/30 03:13:51] ppocr DEBUG: cls num  : 10, elapsed : 0.0408632755279541\n",
      "[2025/03/30 03:13:51] ppocr DEBUG: rec_res num  : 10, elapsed : 0.47242021560668945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "[2025-03-30 03:14:16,449] [    INFO] _internal.py:97 - 127.0.0.1 - - [30/Mar/2025 03:14:16] \"POST /grade_exam HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import cv2\n",
    "import spacy\n",
    "import numpy as np\n",
    "import string\n",
    "import csv\n",
    "import random\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from flask import Flask, request, Response\n",
    "from paddleocr import PaddleOCR\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize models\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "sbert_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "entailment_classifier = pipeline(\"text-classification\", model=\"roberta-large-mnli\", return_all_scores=True)\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def classify_subject(question, candidate_labels=None):\n",
    "    if candidate_labels is None:\n",
    "        candidate_labels = [\"Math\", \"Science\", \"History\", \"Literature\", \"Geography\", \"Art\"]\n",
    "    subject_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "    result = subject_classifier(question, candidate_labels)\n",
    "    return result[\"labels\"][0]\n",
    "\n",
    "def load_advice(filename):\n",
    "    advice_list = []\n",
    "    try:\n",
    "        with open(filename, newline='', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                advice_list.append({\n",
    "                    \"min_score\": float(row[\"min_score\"]),\n",
    "                    \"max_score\": float(row[\"max_score\"]),\n",
    "                    \"subject\": row[\"subject\"],\n",
    "                    \"advice\": row[\"advice\"],\n",
    "                    \"study_plan\": row[\"study_plan\"],\n",
    "                    \"recommended_books\": row[\"recommended_books\"]\n",
    "                })\n",
    "    except Exception as e:\n",
    "        print(\"Advice file error:\", e)\n",
    "    return advice_list\n",
    "\n",
    "def get_advice(score, subject, advice_list):\n",
    "    filtered_advices = [\n",
    "        advice for advice in advice_list \n",
    "        if advice[\"subject\"].lower() == subject.lower() and advice[\"min_score\"] <= score <= advice[\"max_score\"]\n",
    "    ]\n",
    "    if filtered_advices:\n",
    "        return random.choice(filtered_advices)\n",
    "    else:\n",
    "        return {\n",
    "            \"advice\": \"No advice available.\",\n",
    "            \"study_plan\": \"No study plan available.\",\n",
    "            \"recommended_books\": \"No books available.\"\n",
    "        }\n",
    "\n",
    "def ocr_from_array(image):\n",
    "    image = np.ascontiguousarray(image)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    result = ocr.ocr(gray, cls=True)\n",
    "    return \"\\n\".join([line[1][0] for line in result[0]])\n",
    "\n",
    "def preprocess_text(text):\n",
    "    return \" \".join(token.lemma_ for token in nlp(text.lower()) if not token.is_stop and not token.is_punct)\n",
    "\n",
    "def text_to_vector_sbert(text):\n",
    "    return sbert_model.encode(text, convert_to_tensor=True)\n",
    "\n",
    "def compute_similarity(text1, text2):\n",
    "    return util.pytorch_cos_sim(text_to_vector_sbert(text1), text_to_vector_sbert(text2)).item()\n",
    "\n",
    "def contains_keyword(reference, student):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return bool(set(reference.lower().translate(translator).split()) &\n",
    "                set(student.lower().translate(translator).split()))\n",
    "\n",
    "def check_entailment(student, reference):\n",
    "    result = entailment_classifier(f\"{student} </s></s> {reference}\", truncation=True)\n",
    "    return next((item[\"score\"] for item in result[0] if item[\"label\"] == \"ENTAILMENT\"), 0.0)\n",
    "\n",
    "def entity_match(ref_ans, stud_ans):\n",
    "    return bool({ent.text.lower() for ent in nlp(ref_ans).ents} &\n",
    "                {ent.text.lower() for ent in nlp(stud_ans).ents})\n",
    "\n",
    "def extract_numbers(text):\n",
    "    nums = set(re.findall(r'\\d+', text))\n",
    "    number_words = {\"zero\": \"0\", \"one\": \"1\", \"two\": \"2\", \"three\": \"3\", \"four\": \"4\",\n",
    "                    \"five\": \"5\", \"six\": \"6\", \"seven\": \"7\", \"eight\": \"8\", \"nine\": \"9\", \"ten\": \"10\"}\n",
    "    for word in text.lower().split():\n",
    "        if (w := word.strip(string.punctuation)) in number_words:\n",
    "            nums.add(number_words[w])\n",
    "    return nums\n",
    "\n",
    "def is_year(text):\n",
    "    text_clean = text.strip().replace(\".\", \"\")\n",
    "    numbers = re.findall(r'\\d{4}', text_clean)\n",
    "    return len(numbers) == 1 and re.sub(r'\\d{4}', '', text_clean).strip(string.punctuation + \" \") == \"\"\n",
    "\n",
    "def advanced_grade(ref_ans, stud_ans, similarity, threshold=0.8, max_grade=100):\n",
    "    min_correct_score = 50\n",
    "    min_incorrect_score = 30\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    ref_clean = ref_ans.lower().translate(translator).strip()\n",
    "    stud_clean = stud_ans.lower().translate(translator).strip()\n",
    "    base_grade = similarity * max_grade\n",
    "    grade = None\n",
    "    mark = None\n",
    "    if is_year(ref_ans):\n",
    "        ref_years, stud_years = re.findall(r'\\d{4}', ref_ans), re.findall(r'\\d{4}', stud_ans)\n",
    "        if not stud_years or ref_years[0] != stud_years[0]:\n",
    "            grade = 0\n",
    "            if contains_keyword(ref_ans, stud_ans):\n",
    "                grade = max(grade, min_incorrect_score)\n",
    "            mark = \"Incorrect\"\n",
    "        else:\n",
    "            grade = max_grade\n",
    "            mark = \"Correct\"\n",
    "    elif ref_clean == stud_clean:\n",
    "        grade = max_grade\n",
    "        mark = \"Correct\"\n",
    "    elif len(stud_clean.split()) <= 3 and contains_keyword(ref_ans, stud_ans):\n",
    "        grade = max_grade\n",
    "        mark = \"Correct\"\n",
    "    elif extract_numbers(stud_ans) and (extract_numbers(stud_ans) & extract_numbers(ref_ans)):\n",
    "        grade = max_grade\n",
    "        mark = \"Correct\"\n",
    "    elif check_entailment(stud_ans, ref_ans) > 0.9:\n",
    "        grade = max_grade\n",
    "        mark = \"Correct\"\n",
    "    elif entity_match(ref_ans, stud_ans):\n",
    "        grade = max(base_grade, threshold * max_grade)\n",
    "        if grade < min_correct_score:\n",
    "            grade = min_correct_score\n",
    "        mark = \"Correct\"\n",
    "    elif contains_keyword(ref_ans, stud_ans):\n",
    "        if similarity < threshold:\n",
    "            grade = max(base_grade, threshold * max_grade)\n",
    "            if grade < min_correct_score:\n",
    "                grade = min_correct_score\n",
    "            mark = \"Correct\"\n",
    "        else:\n",
    "            grade = min(base_grade + 10, max_grade)\n",
    "            if grade < min_correct_score:\n",
    "                grade = min_correct_score\n",
    "            mark = \"Correct\"\n",
    "    elif similarity >= threshold:\n",
    "        grade = min(base_grade + 10, max_grade)\n",
    "        if grade < min_correct_score:\n",
    "            grade = min_correct_score\n",
    "        mark = \"Correct\"\n",
    "    else:\n",
    "        grade = base_grade\n",
    "        if contains_keyword(ref_ans, stud_ans) and grade < min_incorrect_score:\n",
    "            grade = min_incorrect_score\n",
    "        mark = \"Incorrect\"\n",
    "    if mark == \"Correct\":\n",
    "        ref_word_count = len(ref_ans.split())\n",
    "        stud_word_count = len(stud_ans.split())\n",
    "        if ref_word_count > 0 and stud_word_count < ref_word_count:\n",
    "            ratio = stud_word_count / ref_word_count\n",
    "            grade = grade * ratio\n",
    "            if grade < min_correct_score:\n",
    "                grade = min_correct_score\n",
    "    return (grade, mark)\n",
    "\n",
    "def correct_token(token):\n",
    "    replacements = {\n",
    "        'o': '0', 'O': '0',\n",
    "        'l': '1', 'I': '1', '|': '1',\n",
    "        'z': '2', 'Z': '2',\n",
    "        'e': '3', 'E': '3',\n",
    "        'a': '4', 'A': '4',\n",
    "        'y': '4', 'Y': '4',\n",
    "        's': '5', 'S': '5',\n",
    "        'g': '6', 'G': '6',\n",
    "        't': '7', 'T': '7',\n",
    "        'b': '8', 'B': '8',\n",
    "        'q': '9', 'Q': '9',\n",
    "        'L': '2',\n",
    "        'i': '1'\n",
    "    }\n",
    "    return \"\".join(replacements.get(char, char) for char in token)\n",
    "\n",
    "def parse_reference_answers(text):\n",
    "    ref_dict = {}\n",
    "    lines = text.splitlines()\n",
    "    current_qnum = None\n",
    "    current_question = \"\"\n",
    "    current_answer = \"\"\n",
    "    state = \"question\"\n",
    "    question_pat = re.compile(r'^(?:Question\\s*)?[\\(\\[]?\\s*([A-Za-z0-9]+)[\\)\\]\\-\\.]\\s*(.*)', re.IGNORECASE)\n",
    "    answer_pat = re.compile(r'^(?i)Answer[:\\s]*(.*)')\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        q_match = question_pat.match(line)\n",
    "        if q_match:\n",
    "            if current_qnum is not None:\n",
    "                if not current_question.strip().endswith('?'):\n",
    "                    current_question = current_question.strip() + '?'\n",
    "                ref_dict[current_qnum] = {\"question\": current_question.strip(), \"answer\": current_answer.strip()}\n",
    "            try:\n",
    "                token = q_match.group(1)\n",
    "                current_qnum = int(token)\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    current_qnum = int(correct_token(q_match.group(1)))\n",
    "                except ValueError:\n",
    "                    current_qnum = None\n",
    "            current_question = q_match.group(2).strip()\n",
    "            current_answer = \"\"\n",
    "            if re.search(r'(?i)\\bAnswer[:\\s]*', current_question):\n",
    "                parts = re.split(r'(?i)\\bAnswer[:\\s]*', current_question, maxsplit=1)\n",
    "                current_question = parts[0].strip()\n",
    "                current_answer = parts[1].strip()\n",
    "                state = \"answer\"\n",
    "            else:\n",
    "                state = \"question\"\n",
    "            continue\n",
    "        a_match = answer_pat.match(line)\n",
    "        if a_match:\n",
    "            state = \"answer\"\n",
    "            current_answer += \" \" + a_match.group(1).strip()\n",
    "        else:\n",
    "            if state == \"question\":\n",
    "                current_question += \" \" + line\n",
    "            elif state == \"answer\":\n",
    "                current_answer += \" \" + line\n",
    "    if current_qnum is not None:\n",
    "        if not current_question.strip().endswith('?'):\n",
    "            current_question = current_question.strip() + '?'\n",
    "        ref_dict[current_qnum] = {\"question\": current_question.strip(), \"answer\": current_answer.strip()}\n",
    "    return ref_dict\n",
    "\n",
    "def parse_student_answers(text):\n",
    "    stud_dict = {}\n",
    "    lines = text.splitlines()\n",
    "    stud_pat = re.compile(r'^(?:Question\\s*)?[\\(\\[]?\\s*([A-Za-z0-9]+)[\\)\\]\\-\\.]\\s*(.+)', re.IGNORECASE)\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        m = stud_pat.match(line)\n",
    "        if m:\n",
    "            try:\n",
    "                token = m.group(1)\n",
    "                q_num = int(token)\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    q_num = int(correct_token(m.group(1)))\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            stud_dict[q_num] = m.group(2).strip()\n",
    "    return stud_dict\n",
    "\n",
    "def grade_answers(ref_dict, stud_dict, advice_list, threshold=0.8, max_grade=100):\n",
    "    results = []\n",
    "    for q_num in sorted(ref_dict.keys()):\n",
    "        ref_entry = ref_dict[q_num]\n",
    "        ref_question = ref_entry.get('question', f\"Question {q_num}\")\n",
    "        ref_ans = ref_entry.get('answer', '')\n",
    "        subject = classify_subject(ref_question)\n",
    "        if q_num in stud_dict:\n",
    "            stud_ans = stud_dict[q_num]\n",
    "            ref_proc = preprocess_text(ref_ans)\n",
    "            stud_proc = preprocess_text(stud_ans)\n",
    "            similarity = compute_similarity(ref_proc, stud_proc)\n",
    "            grade, mark = advanced_grade(ref_ans, stud_ans, similarity, threshold, max_grade)\n",
    "            advice_data = get_advice(grade, subject, advice_list)\n",
    "            results.append({\n",
    "                \"question_number\": q_num,\n",
    "                \"question\": ref_question,\n",
    "                \"subject\": subject,\n",
    "                \"reference\": ref_ans,\n",
    "                \"student\": stud_ans,\n",
    "                \"similarity\": similarity,\n",
    "                \"grade\": grade,\n",
    "                \"mark\": mark,\n",
    "                \"advice\": advice_data[\"advice\"],\n",
    "                \"study_plan\": advice_data[\"study_plan\"],\n",
    "                \"recommended_books\": advice_data[\"recommended_books\"]\n",
    "            })\n",
    "        else:\n",
    "            advice_data = get_advice(0, subject, advice_list)\n",
    "            results.append({\n",
    "                \"question_number\": q_num,\n",
    "                \"question\": ref_question,\n",
    "                \"subject\": subject,\n",
    "                \"reference\": ref_ans,\n",
    "                \"student\": \"No answer provided\",\n",
    "                \"similarity\": 0,\n",
    "                \"grade\": 0,\n",
    "                \"mark\": \"Incorrect\",\n",
    "                \"advice\": advice_data[\"advice\"],\n",
    "                \"study_plan\": advice_data[\"study_plan\"],\n",
    "                \"recommended_books\": advice_data[\"recommended_books\"]\n",
    "            })\n",
    "    return results\n",
    "\n",
    "def extract_mcq_answers_from_image(image, num_questions=None):\n",
    "    margin = 50\n",
    "    vertical_gap = 60\n",
    "    header_gap = vertical_gap  \n",
    "    start_x = margin + 50       \n",
    "    horizontal_gap = 100\n",
    "    bubble_radius = 20\n",
    "    inner_radius = bubble_radius - 5  \n",
    "\n",
    "    if num_questions is None:\n",
    "        image_height = image.shape[0]\n",
    "        num_questions = (image_height - 2 * margin - header_gap) // vertical_gap\n",
    "\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "    _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    answers = {}\n",
    "    for q in range(1, num_questions + 1):\n",
    "        y = margin + header_gap + (q - 1) * vertical_gap  \n",
    "        marked_option = None\n",
    "        for idx, option in enumerate([\"A\", \"B\", \"C\", \"D\"]):\n",
    "            x = start_x + idx * horizontal_gap\n",
    "\n",
    "            x1 = max(0, x - inner_radius)\n",
    "            y1 = max(0, y - inner_radius)\n",
    "            x2 = min(thresh.shape[1], x + inner_radius)\n",
    "            y2 = min(thresh.shape[0], y + inner_radius)\n",
    "            region = thresh[y1:y2, x1:x2]\n",
    "\n",
    "            if region.size == 0:\n",
    "                continue\n",
    "\n",
    "            mask = np.zeros(region.shape, dtype=np.uint8)\n",
    "            mask_umat = cv2.UMat(mask)\n",
    "            center_mask = (region.shape[1] // 2, region.shape[0] // 2)\n",
    "            radius_mask = min(center_mask[0], center_mask[1])\n",
    "            cv2.circle(mask_umat, center_mask, radius_mask, 255, -1)\n",
    "            mask = mask_umat.get()\n",
    "\n",
    "            if np.count_nonzero(mask) == 0:\n",
    "                continue\n",
    "            avg = np.mean(region[mask == 255])\n",
    "            \n",
    "            if avg < 150:\n",
    "                marked_option = option\n",
    "                break\n",
    "        if marked_option is not None:\n",
    "            answers[q] = marked_option\n",
    "    return answers\n",
    "\n",
    "def grade_mcq_answers(correct_dict, student_dict, points_per_question=1):\n",
    "    correct_questions = []\n",
    "    incorrect_questions = []\n",
    "    total_questions = len(correct_dict)\n",
    "    score = 0\n",
    "    for q in sorted(correct_dict.keys()):\n",
    "        correct_ans = correct_dict[q]\n",
    "        student_ans = student_dict.get(q, None)\n",
    "        if student_ans is None:\n",
    "            incorrect_questions.append(q)\n",
    "        elif student_ans == correct_ans:\n",
    "            correct_questions.append(q)\n",
    "            score += points_per_question\n",
    "        else:\n",
    "            incorrect_questions.append(q)\n",
    "    total_grade = (score / (total_questions * points_per_question)) * 100 if total_questions > 0 else 0\n",
    "    return {\n",
    "        \"Correct Questions\": correct_questions,\n",
    "        \"Incorrect Questions\": incorrect_questions,\n",
    "        \"Total Grade\": total_grade\n",
    "    }\n",
    "\n",
    "@app.route('/grade_exam', methods=['POST'])\n",
    "def grade_exam():\n",
    "    if 'ref_image' not in request.files or 'stud_image' not in request.files:\n",
    "        return Response(json.dumps({\"Error\": \"Missing one or both image files.\"}),\n",
    "                        status=400, mimetype='application/json')\n",
    "\n",
    "    ref_file = request.files['ref_image']\n",
    "    stud_file = request.files['stud_image']\n",
    "\n",
    "    ref_bytes = np.frombuffer(ref_file.read(), np.uint8)\n",
    "    stud_bytes = np.frombuffer(stud_file.read(), np.uint8)\n",
    "    ref_img = cv2.imdecode(ref_bytes, cv2.IMREAD_COLOR)\n",
    "    stud_img = cv2.imdecode(stud_bytes, cv2.IMREAD_COLOR)\n",
    "\n",
    "    if ref_img is None or stud_img is None:\n",
    "        return Response(json.dumps({\"Error\": \"One or both images could not be processed.\"}),\n",
    "                        status=400, mimetype='application/json')\n",
    "\n",
    "    margin = 50\n",
    "    vertical_gap = 60\n",
    "    header_gap = vertical_gap  \n",
    "    computed_questions = (ref_img.shape[0] - 2 * margin - header_gap) // vertical_gap\n",
    "    mcq_ref = extract_mcq_answers_from_image(ref_img, num_questions=computed_questions)\n",
    "    mcq_stud = extract_mcq_answers_from_image(stud_img, num_questions=computed_questions)\n",
    "    if len(mcq_ref) >= computed_questions // 2 and len(mcq_stud) >= computed_questions // 2:\n",
    "        result = grade_mcq_answers(mcq_ref, mcq_stud)\n",
    "        response = {\n",
    "            \"Exam Type\": \"MCQ\",\n",
    "            \"Results\": result\n",
    "        }\n",
    "    else:\n",
    "        advice_file = r\"E:\\Project\\AI\\Grades\\data\\advice.csv\"\n",
    "        ref_text = ocr_from_array(ref_img)\n",
    "        stud_text = ocr_from_array(stud_img)\n",
    "        ref_answers = parse_reference_answers(ref_text)\n",
    "        stud_answers = parse_student_answers(stud_text)\n",
    "        advice_list = load_advice(advice_file)\n",
    "        results = grade_answers(ref_answers, stud_answers, advice_list, threshold=0.8, max_grade=100)\n",
    "        ordered_results = []\n",
    "        for res in results:\n",
    "            od = OrderedDict([\n",
    "                (\"Question Number\", res.get(\"question_number\")),\n",
    "                (\"Question\", res.get(\"question\")),\n",
    "                (\"Subject\", res.get(\"subject\")),\n",
    "                (\"Reference\", res.get(\"reference\")),\n",
    "                (\"Student\", res.get(\"student\")),\n",
    "                (\"Similarity\", res.get(\"similarity\")),\n",
    "                (\"Grade\", res.get(\"grade\")),\n",
    "                (\"Mark\", res.get(\"mark\")),\n",
    "                (\"Advice\", res.get(\"advice\")),\n",
    "                (\"Study Plan\", res.get(\"study_plan\")),\n",
    "                (\"Recommended Books\", res.get(\"recommended_books\"))\n",
    "            ])\n",
    "            ordered_results.append(od)\n",
    "        if results:\n",
    "            overall_grade = sum(res[\"grade\"] for res in results) / len(results)\n",
    "        else:\n",
    "            overall_grade = 0\n",
    "        response = {\n",
    "            \"Exam Type\": \"Handwritten\",\n",
    "            \"Results\": ordered_results,\n",
    "            \"Overall Grade\": overall_grade\n",
    "        }\n",
    "    return Response(json.dumps(response, indent=4, ensure_ascii=False), mimetype='application/json')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradesENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
